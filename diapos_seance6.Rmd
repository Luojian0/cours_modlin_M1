---
title: "ANOVA à 2 facteur"
subtitle: "Séance 6 de *modèles linéaires*"
author: "Florent Chuffart & Magali Richard"
date: "`r Sys.Date()`"
output: 
  slidy_presentation:

# output: html_document
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, width = 75)
knitr::opts_chunk$set(echo = TRUE, fig.width=15, fig.heigh=5, fig.align='center', dev='png', dpi = 95,
echo=FALSE, results="hide")

```

---

# Organisation

## Pré-requis
 
 - R https://cran.r-project.org 
 - RStudio https://www.rstudio.com

## Evaluation

 - individuelle sur un jeu de données aprés 4 séances de cours 
 - data challenge à la fin des séances

## Supports

 - https://github.com/magrichard/cours_modlin_M1


## Découpage prévisionnel

Séance 1 - 3h (10/01) Régression linéaire simple

Séance 2 - 3h (24/01) Régression linéaire multiple

Séance 3 - 3h (31/01) Anova 1 facteur / partie A

Séance 4 - 3h (14/02) Anova 1 facteur / partie B

Séance 5 - 3h (21/02) Data challenge

Séance 6 - 3h (07/03) Anova 2 facteurs

Séance 7 - 3h (11/03) Anova multiple

Séance 8 - 3h (14/03) Anova facteurs emboités


---

# Plan

### ANOVA à 2 facteurs

1. Rappels ANOVA à un facteur
2. Introduction ANOVA 2 facteurs
3. ANOVA 2 facteurs avec répétion
4. Vérification des conditions
5. Comparaisons multiples
6. ANOVA 2 facteurs sans répétition

---
 
# I. Rappels ANOVA à un facteur

$$Y \sim X$$

*X* - L’analyse de la variance (ANOVA) se caractérise par des variables explicatives **qualitatives** (Ex : sexe, couleur des yeux).

*Y* - Dans les deux cas (ANOVA et regression linéaire) la variable expliquée est quantitative (Ex : taille, poids).

L’**ANOVA** à un facteur est un à la fois un **modèle** statistique fondé sur la décomposition de la variance et **test** statistique permettant de comparer les moyennes de plusieurs variables aléatoires indépendantes, gaussiennes et de même variance.

### Un modèle statistique

$$Y_{ij} = \mu + \alpha_i + \epsilon_{ij}$$


où : $$\sum_{i=1}^I \alpha_i = 0$$ 

Ainsi : $$\mu_i = \mu + \alpha_i, i=1,...,I$$


### Test de l'ANOVA

**1) Tableau de l’analyse de la variance**

| Source de variation   | sc        | ddl  |  cm  | $F_{obs}$
| :-------------------- | :-------: | :--: | :--: | ---:
| Due au facteur        | $sc_{F}=\sum(\overline{y}_i-\overline{y}_n)^2$  | $I-1$  | $cm_{F}=\frac{sc_{F}}{I-1}$ | $\frac{cm_{F}}{cm_{res}}$
| Résiduelle            | $sc_{res}=\sum(y_{ij}-\overline{y}_i)^2$| $n-I$  | $cm_{res}=\frac{sc_{res}}{n-I}$ 
| Totale                | $sc_{tot}=\sum(y_{ij}-\overline{y}_n)^2$| $n-1$ 

**2) Test**

$\mathcal{H}_0 : \mu_1 = \mu_2 = ... = \mu_I$ contre $\mathcal{H}_1$ : les moyennes $\mu_i$ ne sont pas toutes égales 

Satistique du test: $F_{obs} = \frac{cm_{F}}{cm_{res}}$

Pour un seuil donné $\alpha$, les tables de Fisher nous fournissent une valeur critique $c$ telle que
$\mathbb{P}_{H_0} [F \leq c] = 1 -\alpha$ Alors nous décidons :

- si $F_{obs} < c$, $\mathcal{H}_0$ est vraie,
- si $F_{obs} \geq c$, $\mathcal{H}_1$ est vraie,

**3) Hypothèses du test**

Les résidus $\widehat{e_{ij}}$ sont associés, sans en être des réalisations, aux variables erreurs $\epsilon_{ij}$ qui sont inobservables et satisfont aux 3 conditions suivantes :

- Indépendance
- Normalité
- Homoscedasticité


---

# II. Introduction ANOVA à 2 facteurs
## Exemple


On souhaite expliquer le nombre de rupture de fil de chaîne (`break`) en fonction du type de laine (`wool`) et de la tension exercée (`tension`). 


```{r results="verbatim", echo=TRUE}
data(warpbreaks)
attach(warpbreaks)
DT::datatable(warpbreaks)
```

Nous nous proposons d’utiliser l’analyse de la variance à deux facteurs. Nous observons trois variables :

- deux d’entre elles sont des variables contrôlées, le type de laine, qualitative à deux modalités, et la tension qui peut être considérée comme qualitative à trois modalités.
- La troisième variable est une réponse quantitative.

On commence par visualiser les données. 

```{r results="verbatim", echo=TRUE}
par(mfrow=c(1,2))
plot(wool,breaks)
plot(tension,breaks)
```

La visualisation des eff􏰀ets du couple (wool,tension) sur la moyenne de la variable breaks est la suivante :

```{r results="verbatim", echo=TRUE}
par(mfrow=c(1,2))
interaction.plot(wool,tension,breaks)
interaction.plot(tension,wool,breaks)
```

Les lignes n'étant pas parallèles, nous envisageons un modèle avec interaction des facteurs. 

Pour terminer, nous regardons quel type de plan expérimental nous avons.

```{r results="verbatim", echo=TRUE}
table(wool,tension)
```

Nous avons un plan équilibré complet, où toutes les observations sont supérieures à 1. Donc l’analyse de la variance à deux facteurs (type de laine et tension) croisés, avec interaction, peut convenir, entre autres méthodes d’analyse de ces données.

---
# III. ANOVA 2 facteurs avec répétition
## Contexte

Dans l’étude des effets simultanés d’un facteur à $I$ modalités et d’un facteur à $J$ modalités sur une variable quantitative $Y$ , supposons que $Y$ suive des lois normales, a priori différentes dans les $IJ$ populations disjointes déterminées par la conjonction de deux modalités des facteurs étudiés. Supposons que, dans la population correspondant à la modalité d’ordre $i$ du premier facteur et à la modalité d’ordre $j$ du deuxième facteur, nous ayons :

$\mathcal{L}(Y) = \mathcal{N}(\mu_{ij},\sigma^2)$ pour $i = 1,...,I$ et $j=1,..,J$.

Pour mettre en évidence les éventuelles différences entre le comportement de la variable $Y$ dans les $I$ modalités du premier facteur, dans les $J$ modalités du deuxième facteur, ou encore dans l’interaction entre les deux facteurs, nous considérons des échantillons indépendants de même taille $K$ de la variable $Y$ dans chacune des $IJ$ populations , soit au total un n-échantillon avec $n = IJK$.

---
# III. ANOVA 2 facteurs avec répétition
## Modèle statistique

$$Y_{ij} = \mu + \alpha_i + \beta_j +(\alpha\beta)_{ij} + \epsilon_{ijk}$$

pour $i = 1,...,I$, $j=1,..,J$ et $k = 1,..,K$ avec, pour éviter une surparamétrisation, les contraintes:
$$\sum_{i=1}^I \alpha_i = \sum_{j=1}^J \beta_j = \sum_{i=1}^I (\alpha\beta)_{ij_0}= \sum_{j=1}^J (\alpha\beta)_{i_0j} = 0$$ 
pour $i_0 = 1,...,I$ et $j_0 = 1,...,J$

---
# III. ANOVA 2 facteurs avec répétition
## Hypothèses du modèle

Les variables $\epsilon_{ijk}$ sont ainsi supposées être indépendantes et suivre une loi normale $ \mathcal{N}(\mu_{ij},\sigma^2)$.
Leurs réalisations, notées $e_{ijk}$ , sont considérées comme les erreurs de mesure, elles sont inconnues et vérifient :

$$y_{ijk} = \mu + e_{ijk}$$
Pour $i = 1,...,I$, $j=1,..,J$ et $k = 1,..,K$ 

---
# III. ANOVA 2 facteurs avec répétition
## Les 3 tests

L’analyse de la variance à deux facteurs avec répétitions permet trois tests de Fisher

### Test 1

Nous testons l’effet du premier facteur $F_1$ : Nous testons l’égalité des $I$ paramètres $\alpha_i$ correspondant aux $I$ modalités du premier facteur

$\mathcal{H}_0$ : les paramètres $\alpha_i$ sont tous nuls 

contre

$\mathcal{H}_1$ : les paramètres $\alpha_i$ ne sont pas tous nuls.

### Test 2

Nous testons l’effet du deuxième facteur $F_2$ : Nous testons l’égalité des $J$ paramètres $\beta_j$ correspondant aux $J$ modalités du premier facteur

$\mathcal{H}_0$ : les paramètres $\beta_j$ sont tous nuls 

contre

$\mathcal{H}_1$ : les paramètres $\beta_j$ ne sont pas tous nuls.

### Test 3

Nous testons l’effet de l'interaction entre les facteurs $F_1$ et $F_2$.

$\mathcal{H}_0$ : les $IJ$ paramètres $(\alpha\beta)_{ij}$ sont tous nuls 

contre

$\mathcal{H}_1$ : les $IJ$ paramètres $(\alpha\beta)_{ij}$ ne sont pas tous nuls.

---
# III. ANOVA 2 facteurs avec répétition
## Notations

$$\overline{Y}=\frac{1}{n}\sum_{i,j,k}Y_{ijk}$$

$\overline{Y}_{ij\cdot}=\frac{1}{K}\sum_{k}Y_{ijk}$, $\overline{Y}_{i\cdot\cdot}=\frac{1}{JK}\sum_{j,k}Y_{ijk}$, 
$\overline{Y}_{\cdot j\cdot}=\frac{1}{IK}\sum_{i,k}Y_{ijk}$

$SC_T=\sum_{i,j,k}(Y_{ijk}-\overline{Y})^2$ , $SC_R=\sum_{i,j,k}(Y_{ijk}-\overline{Y}_{ij\cdot})^2$ 

$SC_{\alpha}=\sum_{i,j,k}(\overline{Y}_{i\cdot\cdot}-\overline{Y})^2$ , $SC_{\beta}=\sum_{i,j,k}(Y_{\cdot j\cdot}-\overline{Y})^2$ 

$SC_{\alpha\beta}=\sum_{i,j,k}(\overline{Y}_{ij\cdot} - \overline{Y}_{i\cdot\cdot} - \overline{Y}_{\cdot j \cdot}-\overline{Y})^2$ 


---
# III. ANOVA 2 facteurs avec répétition
## Valeurs numériques

Les calculs sont à réaliser avec les valeurs numériques suivantes:

$\overline{y} = \frac{1}{IJK}\sum_{i,j,k}y_{ijk}$, $\overline{y}_{ij\cdot} = \frac{1}{K}\sum_{k}y_{ijk}$

$\overline{y}_{i\cdot\cdot} = \frac{1}{JK}\sum_{j,k}y_{ijk}$, $\overline{y}_{\cdot j\cdot} = \frac{1}{IK}\sum_{i,k}y_{ijk}$

---
# III. ANOVA 2 facteurs avec répétition
## Equation de l'ANOVA

Léquation de l'anbalyse de la variance devient pour ce modèle : $$SC_T = SC_R + SC_\alpha + SC_\beta + SC_{\alpha\beta}$$

- la somme $SC_T$ , la **somme totale**, mesure la somme des carrés des écarts à la moyenne globale, toutes causes confondues,

- la somme $SC_R$, **la somme résiduelle**, cumule les carrés des écarts des différentes observations à la moyenne de l’échantillon dont elles font partie. Dans la somme totale elle représente la part de la dispersion due aux **fluctuations individuelles**.

- la somme $SC_\alpha$, la **somme due au premier facteur**, ou somme entre modalités du facteur $F_\alpha$, mesure l’effet du premier facteur.

- la somme $SC_\beta$, ou **somme due au deuxième facteur**, ou somme entre modalités du facteur $F_\beta$, mesure l’effet du deuxième facteur.

- la somme $SC_{\alpha\beta}$ mesure l’effet de **l’interaction entre les deux facteurs**.

---
# III. ANOVA 2 facteurs avec répétition
## Propriétés

$$\mathcal{L}_{\mathcal{H}_0}\Big(\frac{\frac{SC_\alpha}{I-1}}{\frac{SC_R}{IJ(K-1)}}\Big) = \mathcal{F}_{(I-1),IJ(K-1)}$$
$$\mathcal{L}_{\mathcal{H}_0}\Big(\frac{\frac{SC_\beta}{J-1}}{\frac{SC_R}{IJ(K-1)}}\Big) = \mathcal{F}_{(J-1),IJ(K-1)}$$

$$\mathcal{L}_{\mathcal{H}_0}\Big(\frac{\frac{SC_\alpha\beta}{(I-1)(J-1)}}{\frac{SC_R}{IJ(K-1)}}\Big) = \mathcal{F}_{(I-1)(J-1),IJ(K-1)}$$

---

# III. ANOVA 2 facteurs avec répétition

## Tableau de l'ANOVA



Pour un seuil donné $\alpha$, les tables de Fisher nous fournissent une valeur critique $c$ telle que
$\mathbb{P}_{H_0} [F \leq c] = 1 -\alpha$ Alors nous décidons :

- si $F_{obs} < c$, $\mathcal{H}_0$ est vraie,
- si $F_{obs} \geq c$, $\mathcal{H}_1$ est vraie.

### Tableau de l'anova


| Source de variation     | sc                   | ddl           |  cm                                                    | $F_{obs}$                          | $F_c$
| :---------------------- | :------------------: | :-----------: | :----------------------------------------------------: | :--------------------------------: | ---------------: 
| Due à $F_\alpha$        | $sc_\alpha$          | $I-1$         | $cm_{\alpha}=\frac{sc_{\alpha}}{I-1}$                  | $\frac{cm_{\alpha}}{cm_{R}}$       | $c_\alpha$
| Due à $F_\beta$         | $sc_\beta$           | $J-1$         | $cm_{\beta}=\frac{sc_{\beta}}{J-1}$                    | $\frac{cm_{\beta}}{cm_{R}}$        | $c_\beta$
| Due à $F_{\alpha\beta}$ | $sc_\alpha\beta$     | $(I-1)(J-1)$  | $cm_{\alpha\beta}=\frac{sc_{\alpha\beta}}{(I-1)(J-1)}$ | $\frac{cm_{\alpha\beta}}{cm_{R}}$  | $c_\alpha\beta$
| Résiduelle              | $sc_{R}$             | $IJ(K-1)$     | $cm_{R}=\frac{sc_{R}}{IJ(K-1)}$ 
| Totale                  | $sc_{T}$             | $n-1$ 

---

# III. ANOVA 2 facteurs avec répétition
## Exemple

```{r results="verbatim", echo=TRUE}
m = aov(breaks~wool*tension)
summary(m)
coef(m)

```

Le modèle est significatif: les facteurs ont une influence sur la variable expliquée. On peut remarquer que le coefficient de la variable `wool` n'est pas significatif. Cependant le coefficient des effets croisés `wool:tension` étant significatif, la variable `wool` influence significativmenet la variable `breaks`.

---

# IV. Vérification des conditions

Pour ce modèle, l’estimation des moyennes théoriques $\mu_{ij}$ se fait par les moyennes observées $\overline{y}_{ij\cdot}$ (« valeurs ajustées »). Les résidus sont alors donnés par l’expression :
$\widehat\epsilon_{ijk} = y_{ijk}-\overline{y}_{ij\cdot}$, $i =1,...,I$;$j =1,...,J$;$k =1,...,K$.
Leur normalité et l’homogénéité des variances se vérifient par les mêmes méthodes que pour une analyse de la variance à un facteur.

- Indépendance
- Normalité
- Homoscedasticité


```{r results="verbatim", echo=TRUE}
par(mfrow=c(2,2))
m = aov(breaks~wool*tension)
plot(m)
```

Après visualisation graphique, la normalité des résidus semble être respectée, par contre, l'homogénéité de la variance ne semble pas vérifiée.

## Normalité des résidus

```{r results="verbatim", echo=TRUE}
shapiro.test(m$residuals)
```

## Homogénéité des variances

```{r results="verbatim", echo=TRUE}
bartlett.test(breaks,wool)
bartlett.test(breaks,tension)
```

Cela confirme les observations graphiques.

## Transformation des variables

Nous testons une transformation des variable: la transformation log.

```{r results="verbatim", echo=TRUE}
log_breaks = log(breaks)
par(mfrow=c(1,2))
hist(breaks)
hist(log_breaks)
par(mfrow=c(2,2))
m_log = aov(log_breaks~wool*tension)
plot(m_log)
shapiro.test(m_log$residuals)
bartlett.test(log_breaks,wool)
bartlett.test(log_breaks,tension)
```

---

# V. Comparaisons multiples

Lorsque l’effet d’un facteur a été mis en évidence, le test de Tukey ou celui de Dunnett s’applique chaque fois que le nombre d’observations le permet, à l’aide de la même statistique. Les effectifs $n_i$ et $n_{i′}$ sont alors ceux des classes comparées.

---

# V. Comparaisons multiples
## Exemple 

```{r results="verbatim", echo=TRUE}
res<-lsmeans::lsmeans(m_log,~wool*tension)
pairs(res)
```

```{r results="verbatim", echo=TRUE}
plot(res)
```

Il apparaît que les diff􏰁érences ente les groupes sont peu signi􏰂catives, seules 3 p-valeurs corrigées étant inférieures à 5%. On constate que la principale diff􏰁érence est entre les groupes A,L et B,H. 

C'est la différence entre ces deux groupes qui expliaue notamment l'influence du facteur `wool`.
Au vu des graphiques d'interactions, ce qui nous intéresse est notamment de voir si les groupes A,M et B,M sont similaires. 

La p-valeur de 0.8821 nous confime que la différence n'est pas significative

On peut également regarder l'infl􏰃uence de chaque facteur conditionnellement à l'autre facteur. Les résultats obtenus sont donnés ci-après.

```{r results="verbatim", echo=TRUE}
res_w = lsmeans::lsmeans(m_log,~wool | tension)
pairs(res_w)
plot(res_w)
res_t = lsmeans::lsmeans(m_log,~tension | wool)
pairs(res_t)
plot(res_t)
```

---

# VI. ANOVA 2 facteurs sans répétition

Dans le cas où nous étudions l’effet simultané de deux facteurs à, respectivement, $I$ et $J$ modalités et que nous disposons d’une seule observation pour chaque population, c’est à dire
$K = 1$, les résultats du paragraphe précédent ne sont plus valables. Nous devons supposer que l’interaction entre les deux facteurs est nulle. Partant du même modèle, nous écrivons plus simplement 

$$Y_{ij} = \mu + \alpha_i + \beta_j  + \epsilon_{ijk}$$

 avec les contraintes:
$$\sum_{i=1}^I \alpha_i = \sum_{j=1}^J \beta_j  = 0$$ 

Remarquons que l’expression définissant, dans le cas avec répétitions, la somme des carrés associée à l’interaction, est associée ici à la somme des carrés de la résiduelle.

| Source de variation     | sc                   | ddl           |  cm                                                    | $F_{obs}$                          | $F_c$
| :---------------------- | :------------------: | :-----------: | :----------------------------------------------------: | :--------------------------------: | ---------------: 
| Due à $F_\alpha$        | $sc_\alpha$          | $I-1$         | $cm_{\alpha}=\frac{sc_{\alpha}}{I-1}$                  | $\frac{cm_{\alpha}}{cm_{R}}$       | $c_\alpha$
| Due à $F_\beta$         | $sc_\beta$           | $J-1$         | $cm_{\beta}=\frac{sc_{\beta}}{J-1}$                    | $\frac{cm_{\beta}}{cm_{R}}$        | $c_\beta$
| Résiduelle              | $sc_{R}$             | $(I-1)(J-1)$     | $cm_{R}=\frac{sc_{R}}{(I-1)(J-1)}$ 
| Totale                  | $sc_{T}$             | $IJ-1$ 



---

# Réferences

Ce cours s’inspire des références suivantes :

- Frédéric Bertrand & Myriam Maumy-Bertrand
- Franck Picard
- Irenne Ganaz

